---
date: "2023-06-16"
output:
  officedown::rdocx_document:
    reference_docx: "../../../NRR_Template_Simple.docx"
    tables:
      style: nrps Table cells
      caption: 
        style: nrps Table caption
    plots:
      style: Normal
      align: center
      caption:
        style: Image Caption
        pre: 'Figure'
        sep: '. '
params:
  PARK: "SAGW"
  YEAR: 2022
---

```{r setup, include = FALSE, echo = FALSE, message = FALSE, warning = FALSE}

knitr::opts_knit$set(root.dir = "../../../../" )
knitr::opts_chunk$set(dev = "ragg_png")

library(lubridate)
library(tidyverse)
library(pander)
library(terra)
library(spOccupancy)
library(tidyterra)
library(officer)
library(officedown)
library(flextable)

# set_flextable_defaults(font.family = "Arial",
#                        font.size = 9)


```

```{r data-formatting, echo = FALSE}

source("src/functions.R")
source("src/photo-data/format-mammal-data.R")

PARK <- params$PARK
YEAR <- params$YEAR

```

---
title: "Summary of camera trap data, `r PARK`, `r YEAR`"
---

# Effort
```{r effort, echo = FALSE}

# Park long name
PARKL <- ifelse(PARK == "SAGW", 
                "the Tucson Mountain District of Saguaro National Park",
                ifelse(PARK == "CHIR", "Chiricahua National Monument",
                       "Organ Pipe Cactus National Monument"))

# Subset events data and add a numeric camera ID
events <- events %>%
  filter(Park == PARK, d_yr == YEAR) %>%
  mutate(locnum = as.numeric(as.factor(StdLocName))) %>%
  as.data.frame()
deploy_start <- format(min(events$d_date), "%d %B")
deploy_end <- format(max(events$d_date), "%d %B")
retr_start <- format(min(events$r_date), "%d %B")
retr_end <- format(max(events$r_date), "%d %B")

# Load sampling occasion data
occasions <- read.csv("data/occasions/occasions-all-parks.csv")
occasions <- occasions %>%
  filter(Park == PARK) %>%
  filter(yr %in% YEAR) %>%
  mutate(start_yday = yday(start),
         end_yday = yday(end),
         mid_yday = round((start_yday + end_yday)/2)) %>%
  arrange(yr, occasion) 
season_start <- format(as.Date(occasions$start[1]), "%d %B")
season_end <- format(as.Date(occasions$end[nrow(occasions)]), "%d %B")

# Function to create chart with deployments
ggcust_segs <- function(dat, park, year, xlims, occ){
  ggplot() +
    geom_segment(filter(dat, Park == park & d_yr == year),
                 mapping = aes(x = d_date, xend = r_date, y = locnum, yend = locnum),
                 linewidth = 0.3, color = "dodgerblue3") + 
    geom_segment(filter(dat, Park == park & d_yr == year),
                 mapping = aes(x = d_date, xend = d_date, y = locnum+0.4, yend = locnum-0.4),
                 linewidth = 0.3, color = "dodgerblue3") + 
    geom_segment(filter(dat, Park == park & d_yr == year),
                 mapping = aes(x = r_date, xend = r_date, y = locnum+0.4, yend = locnum-0.4),
                 linewidth = 0.3, color = "dodgerblue3") +
    geom_vline(xintercept = as.Date(occ$start), color = "gray50") + 
    geom_vline(xintercept = as.Date(occ$end[nrow(occ)]), color = "gray50") +
    labs(x = "", y = "Camera number") + 
    scale_x_date(limits = xlims, date_labels = "%b") +
    theme(text=element_text(size = 10),
          axis.title.x=element_blank(),
          plot.margin = margin(0.1, 0.2, 0.2, 0.2, unit = "cm"))
}

xmin <- paste0(YEAR, "-01-01")
if (PARK == "SAGW") {
  xmax <- paste0(YEAR, "-03-15")
} else {
  xmax <- paste0(YEAR, "-12-31")
}

segs <- ggcust_segs(events, PARK, YEAR, xlims = as.Date(c(xmin, xmax)),
                    occ = occasions)
```

A total of `r nrow(events)` cameras were deployed in SAGW between 
`r deploy_start` and `r deploy_end` and were retrieved between 
`r retr_start` and `r retr_end`, `r YEAR`. We delineated a total of 
`r nrow(occasions)` sampling occasions that were each `r occasions$duration[1]` 
days long.

```{r deployment-table, echo = FALSE}

occ_short <- occasions %>% 
  select(c(occasion, start, end)) %>%
  rename(Occasion = occasion,
         Start = start,
         End = end)
occ_ftable <- flextable(occ_short)
occ_ftable <- flextable::align(occ_ftable, align = "left", part = "all")
autonum = run_autonum(seq_id = "table", bkm = NULL)
occ_ftable <- set_caption(occ_ftable, 
                          caption = paste0("Start and end dates for each sampling occasion in ",
                                 PARKL, ", ", YEAR, "."))

```

```{r tabplot, echo = FALSE, ft.align = "left", tab.id = "table"}

occ_ftable %>% autofit()

```

<br>

**Figure 1.** Camera deployments and sampling occasions in `r PARKL`, 
`r YEAR`. Each horizontal blue line represents the period over which a camera 
was operational, from the date the camera was deployed through the date the
camera was retrieved. Gray vertical lines denote the beginning and end of 
the `r nrow(occasions)` consecutive sampling occasions.

```{r deployment-plot, fig.width = 5, fig.height = 3.5, dpi = 300, echo = FALSE}
segs
```

# Detections
```{r detections, message = FALSE, warning = FALSE, echo = FALSE}

# Clean up species table
species <- species %>%
  select(-n)
species$Species[species$Species_code == "SKUNK"] <- "Mephitidae"
species$Species[species$Species_code == "UNCA"] <- "Canidae"

# Filter detection data
dat <- dat %>%
  filter(Park == PARK & yr == YEAR) %>%
  filter(obsdate >= occasions$start[1] & 
           obsdate <= occasions$end[nrow(occasions)])
nphotos <- dat %>%
  group_by(Species_code) %>%
  summarize(n_photos = length(datetime),
            n_locs = length(unique(LocationName))) %>%
  arrange(desc(n_photos)) %>%
  left_join(species, by = "Species_code") %>%
  relocate(Common_name:Species, .before = n_photos) %>%
  data.frame()

# Look at detection data for various species
# Where detection is max of one per sampling occasion at each location
detects <- read.csv("output/species-detections-byparkyr.csv", header = TRUE)
detects <- detects %>%
  dplyr::filter(Park == PARK & yr == YEAR) %>%
  select(c(spp, ndetects)) %>%
  rename(Species_code = spp,
         n_detects = ndetects)

nphotos <- nphotos %>%
  left_join(detects, by = "Species_code") %>%
  relocate(n_detects, .after = n_photos) %>%
  select(-Species_code)

```

We detected a total of `r nrow(nphotos)` mammal species on the `r nrow(events)`
cameras during the `r nrow(occasions)` sampling occasions. 

<br>

**Table 2.** Mammal species detected in `r PARKL` between `r season_start` and
`r season_end`, `r YEAR`. No. photos is the total number of photographs obtained 
(multiple photos may occur at the same camera location in the same day). No.
detections is the number of detections that could be used in an occupancy 
modeling framework (maximum of one photographic detection per camera location 
per sampling period). No. locations is the unique number of camera locations 
where the species was photographed.

```{r detections-table, echo = FALSE}

colnames(nphotos) <- c("Common name", "Scientific name", "No. photos",
                       "No. detections", "No. locations")
pander(nphotos, 
       justify = c("left", "left", "center", "center", "center"),
       emphasize.italics.cols = 2,
       style = "simple")

```

# Modeling approach

## Occupancy models

```{r data-prep, echo = FALSE}

# Get list of species that we ran occupancy models for (and list of files with 
# model output)
spp_rds <- list.files(path = "output/single-season-models/", 
                      pattern = ".rds",
                      full.names = FALSE)
spp_table <- data.frame(Species_code = str_sub(spp_rds, 6, 9))
spp_table$common <- species$Common_name[match(spp_table$Species_code,
                                              species$Species_code)]
nspp <- nrow(spp_table)

# Extract MCMC parameters from one of these model objects
model_list <- readRDS(paste0("output/single-season-models/", spp_rds[1]))
n_samples <- model_list$model$n.samples
n_thin <- model_list$model$n.thin
n_burn <- model_list$model$n.burn
n_chains <- model_list$model$n.chains
n_post <- model_list$model$n.post

# Load multi-layer raster with spatial data for park
park_raster <- readRDS(paste0("data/covariates/spatial-cov-", PARK, ".rds"))
# We have two distance-to-boundary layers, one that applies to the entire park
# boundary and one that applies to boundaries that are adjacent to unprotected
# lands (boundaryUP). For now, we'll remove the original boundary layer.
park_raster <- subset(park_raster, "boundary", negate = TRUE)
names(park_raster)[names(park_raster) == "boundaryUP"] <- "boundary"

# Extract dataframe with covariate values at each camera location
spatial_covs <- model_list$data$occ.covs

# Load general information about covariates
covariates <- read.csv("data/covariates/covariates.csv")

```

For each species with a sufficient number of detections (here, `r nspp` 
species), we used single-season occupancy models to estimate the probability of 
occurrence and the probability of detection given occurrence (MacKenzie et al. 
2002). To estimate these parameters, we generated encounter histories for each 
camera location, where a "1" denotes that the species was detected at least once 
during a sampling occasion and a "0" indicates that the species was not 
detected. For example, an encounter history of "10011" would indicate that a 
species was photographed at least once during the first, fourth, and fifth 
sampling occasions and was not photographed during the second and third sampling 
occasions. 

We used a Bayesian framework to estimate model parameters, as this made it 
easier to estimate derived parameters (e.g., proportion of area occupied across 
the entire park) with associated uncertainties and to incorporate random effects 
that can account for uncertainties beyond that explained by covariates in the 
model. We fit models in R using the spOccupancy package (Doser et al. 2022). For 
each model, we ran `r n_chains` Markov chains initiated at random values for 
`r n_samples` iterations. We discarded the first `r n_burn` iterations and 
retained 1 of every `r n_thin` iterations thereafter, using the remaining 
`r n_chains * n_post` samples (across all the chains) to summarize the posterior 
distribution.

## Model selection

We identifed a number of spatial covariates for `r PARKL` that could explain
variation in occurrence probabilities, detection probabilities, or both.

Something about where we obtained spatial data?

- candidate model set (general)
- how a model for inference was selected


# Species 1 (create species sections in a loop)

```{r CALA-test-model, echo = FALSE}

i = 1
SPECIES <- spp_table$Species_code[i]
spp_name <- tolower(spp_table$common[i])
spp_plural <- paste0(spp_name, "s")

# Load best model and attributes
model_list <- readRDS(paste0("output/single-season-models/", PARK, "-",
                             SPECIES, "-", YEAR, ".rds"))
best <- model_list$model
psi_model <- model_list$psi_model
p_model <- model_list$p_model

# Extract names of covariates (with and without "_z" subscripts) from best model
psi_covs_z <- create_cov_list(psi_model)
if (length(psi_covs_z) == 1 & any(psi_covs_z == "1")) {
  psi_covs_z <- character(0)
  psi_covs <- character(0)
} else {
  psi_covs <- psi_covs_z %>% str_remove_all(pattern = "_z")
}
p_covs_z <- create_cov_list(p_model)
if (length(p_covs_z) == 1 & any(p_covs_z == "1")) {
  p_covs_z <- character(0)
  p_covs <- character(0)
} else {
  p_covs <- p_covs_z %>% str_remove_all(pattern = "_z")
}

# Create table with summary stats that can be saved to file
occ_estimates <- parameter_estimates(model = best,
                                     parameter = "occ",
                                     lower_ci = 0.025,
                                     upper_ci = 0.975)
det_estimates <- parameter_estimates(model = best,
                                     parameter = "det",
                                     lower_ci = 0.025,
                                     upper_ci = 0.975)
occ_estimates <- occ_estimates %>%
  rename(Covariate = Parameter) %>%
  mutate(Parameter = "Occurrence", .before = "Covariate")
det_estimates <- det_estimates %>%
  rename(Covariate = Parameter) %>%
  mutate(Parameter = "Detection", .before = "Covariate")
estimates <- rbind(occ_estimates, det_estimates)

# Calculate the number of covariates in each part of the model:
n_covs_occ <- length(psi_covs)
n_covs_occt <- ifelse(n_covs_occ > 1, paste0(n_covs_occ, " covariates"), 
                      ifelse(n_covs_occ == 1, "1 covariate", "no covariates"))
n_covs_det <- length(p_covs)
n_covs_dett <- ifelse(n_covs_det > 1, paste0(n_covs_det, " covariates"), 
                      ifelse(n_covs_det == 1, "1 covariate", "no covariates"))

# Create spatial predictions IF there are spatial covariates in the occurrence
# part of the model. NOTE: this can take several minutes to run.
if (length(psi_covs) > 0) {
  # source("src/single-season-models/spOccupancy-predictions.R")
}

```

## Model used for inference

The highest-ranking model for `r spp_plural` included `r n_covs_occt` in the 
occurrence part of the model and `r n_covs_dett` in the detection part of the
model.

<br>

**Table X.** Parameter estimates (on the logit scale) from a model for 
`r spp_plural` in `r PARKL`, `r YEAR`. SD = Standard deviation; 95% CI = 95% 
credible interval. Rhat values between 1 and 1.05 indicate that the model has 
converged. ESS = effective sample size; values > 400 are usually sufficient. f 
values indicate the proportion of posterior samples that are < 0 if the mean is 
< 0 or the proportion of samples that are > 0 if the mean is > 0. All continuous 
covariates were standardized by their respective means and standard deviations 
prior to analysis.

```{r CALA-test-estimates, echo = FALSE}

estimates %>%
  rename(LowerCI = "Lower95%",
         UpperCI = "Upper95%") %>%
  mutate(across(Mean:UpperCI, function(x) round(x, 2))) %>%
  mutate("95% CI" = paste0(LowerCI, ", ", UpperCI)) %>%
  select(-c(Median, LowerCI, UpperCI, exclude0)) %>%
  relocate("95% CI", .after = SD) %>%
  pander(justify = c(rep("right", 4), "center", rep("right", 3)),
         digits = 2,
         big.mark = "",
         style = "simple")
# Replace entries in the covariate column? (elevation instead of elev_z?)

```

<br>

## Estimated detection probabilities?

```{r CALA-test-det-estimates, echo = FALSE}

alpha_samples <- model_list$model$alpha.samples

# Calculate overall detection probability (for experienced deployment 
# personnel if that was included in the model)
if ("deploy_exp" %in% p_covs) {
  alpha_deploy <- alpha_samples[ ,c("(Intercept)", "deploy_exp")]
  X0 <- as.vector(c(1, 2))
  probs_logit <- alpha_deploy %*% X0
} else {
  probs_logit <- alpha_samples[ ,"(Intercept)"]
}
det_probs <- exp(probs_logit) / (1 + exp(probs_logit))
mean_det <- round(mean(det_probs), 2)
lcl_det <- round(quantile(det_probs, 0.025), 2)
ucl_det <- round(quantile(det_probs, 0.975), 2)

# If covariates are in the model, create objects to describe the effect.
if ("effort" %in% p_covs) {
  if (mean(alpha_samples[,"effort_z"]) > 0) {
    effortpos <- TRUE
  } else {
    effortneg <- TRUE
  }
} else {
  effortpos <- FALSE
  effortneg <- FALSE
}

if ("I(day_z^2)" %in% colnames(alpha_samples)) {
  a <- mean(alpha_samples[,"I(day_z^2)"])
  b <- mean(alpha_samples[,"day_z"])
  inflect <- -b / (2 * a)
  inflectdn <- inflect * sd(rep(occasions$mid_yday, nrow(events))) + mean(occasions$mid_yday)
  inflectday <- parse_date_time(x = paste(YEAR, round(inflectd)), orders = "yj")
  inflectday <- format(as.Date(inflectday), "%d %B")
  if (a < 0) {
    day2max <- TRUE
  } else {
    day2min <- TRUE
  }
} else {
  day2max <- FALSE
  day2min <- FALSE
}

if ("day_z" %in% colnames(alpha_samples) & !"I(day_z^2)" %in% colnames(alpha_samples)) {
  if (mean(alpha_samples[,"day_z"]) > 0) {
    daypos <- TRUE
  } else {
    dayneg <- TRUE
  }
} else {
  daypos <- FALSE
  dayneg <- FALSE
}

# Overall detection probability `r if("deploy_exp" %in% p_covs) {"with experienced
# deployment personnel "}`for `r spp_plural` was `r mean_det` (95% credible
# interval [CI] = `r lcl_det`, `r ucl_det`).
# `r if (day2max) {"Detection probability varied seasonally, increasing initially
# and then decreasing, reaching a maximum on `r inflectday`. "}`
# `r if (day2min) {"Detection probability varied seasonally, decreasing initially
# and then increasing, with minimum detection probabilities on `r inflectday`. "}`
# `r if (daypos) {"Detection probability increased over the course of the
# season. "}`
# `r if (dayneg) {"Detection probability decreased over the course of the
# season. "}`
# `r if(effortpos) {"Detection probability was positively associated with the 
# number of days a camera was operational during each sampling occasion. "}` 
# `r if(effortneg) {"Detection probability was negatively associated with the 
# number of days a camera was operational during each sampling occasion. "}`


```


## Estimated occurrence probabilities

```{r CALA-test-occ-estimates, echo = FALSE}

beta_samples <- model_list$model$beta.samples

# Calculate overall occurrence probability (or for each vegetation class if 
# that's in the model)

# if ("vegclass2" %in% psi_covs) {
#   vegclass_table <- vegclass_estimates(model_list$model,
#                                        parameter = "occ",
#                                        lower_ci = 0.025,
#                                        upper_ci = 0.975)
#   print(vegclass_table)
# } else {
#   probs_logit <- beta_samples[ ,"(Intercept)"]
#   occ_probs <- exp(probs_logit) / (1 + exp(probs_logit))
#   mean_occ <- round(mean(occ_probs), 2)
#   lcl_occ <- round(quantile(occ_probs, 0.025), 2)
#   ucl_occ <- round(quantile(occ_probs, 0.975), 2)
#   paste0("Overall occurrence probability was ", 
#          mean_occ, " (", lcl_occ, ", ", ucl_occ, ").")
# }

```

**Figure X.** Predicted occurrence probabilities for `r spp_plural` in 
`r PARKL`, `r YEAR`.

```{r CALA-test-map, fig.width = 5, fig.height = 3.5, dpi = 150, echo = FALSE}

# map <- ggplot() +
#   geom_spatraster(data = preds_mn, mapping = aes(fill = mean)) + 
#   scale_fill_viridis_c(na.value = "transparent") +
#   labs(fill = "", x = NULL, y = NULL, title = NULL) +
#   theme_bw()
# map + theme(axis.title = element_blank(),
#             title = element_blank())

# Cannot get plot.margin argument in theme to work:
# map + theme(plot.margin = unit(c(0,0,0,0), "lines"))
# This makes all of them too small..
# plot.margin = unit(c(-1, -1, -1, -1), "cm")

```

## Estimated covariate effects on occurrence probabilities

```{r CALA-test-covariate-effects, echo = FALSE}

# Identify continuous covariates in occurrence part of the best model
  psi_continuous <- psi_covs_z[!psi_covs_z %in% c("1", "vegclass2", "vegclass3")]
  psi_cont_unique <- unique(psi_continuous)
  psi_n_cont <- length(psi_cont_unique)
  
  data_list <- model_list$data

# If there are any continuous covariates, create a figure for each:
  if (psi_n_cont > 0) {
    # Loop through each covariate
    for (cov in psi_cont_unique) {
      # Create name of plot:
      plotname <- paste0("marginal_psi_", str_remove(cov, "_z"))
      # Create plot
      assign(plotname, 
             marginal_plot_occ(covariate = cov, 
                               model = best, 
                               data_list = data_list,
                               covariate_table = covariates,
                               central_meas = mean))
    } 
  }

# Can view these plots, calling them by name. Available plots listed here:
  # str_subset(ls(), "marginal_psi_")

# If vegetation classes were included as covariates in the model, extract
# occurrence probabilities for each class
  if (sum(str_detect(psi_covs, "veg")) > 0) {
    occprobs_veg <- vegclass_estimates(model = best, 
                                       parameter = "occ")
  }

# If there are no covariates in the model (ie, a null model), print overall 
# occurrence probability
  if (psi_n_cont == 0 & length(psi_covs) == 0) {
    overall_occ <- mean_estimate(model = best, 
                                 parameter = "occ",
                                 lower_ci = 0.025,
                                 upper_ci = 0.975)
  }  

```

**Figure X.** Effect of XXX on occurrence probabilities for `r spp_plural` in 
`r PARKL`, `r YEAR`.

```{r CALA-test-marginal-psi1, fig.width = 5, fig.height = 3.5, dpi = 150, echo = FALSE}

marginal_psi_elev

```





```{r echo = FALSE, results = "asis"}
# input <- data.frame(
#   name = LETTERS[1:4],
#   data = runif(n = 4),
#   text = replicate(4, paste(sample(x = LETTERS, size = 100, replace = TRUE), collapse = "")),
#   stringsAsFactors = FALSE)
# 
# template <- "## This is section %s
# Section data is `%0.2f`.
# Additional section text is: %s.
# 
# " # don't forget the newline
# 
# for (i in seq(nrow(input))) {
#   current <- input[i, ]
#   cat(sprintf(template, current$name, current$data, current$text))
# }
```



```{r, mtcars-plots, echo = FALSE, results = 'asis'}
# for (i in names(mtcars)) {
#   cat('\n\n# Summary of the variable `', i, '`\n\n')
#   x <- mtcars[, i]
#   if (length(unique(x)) <= 6) {
#     cat('`', i, '` is a categorical variable.\n\n')
#     plot(table(x), xlab = i, ylab = 'Frequency', lwd = 10)
#   } else {
#     cat('Histogram for the continuous variable `', i, '`.\n\n')
#     hist(x, xlab = i, main = '')
#   }
# }
```




